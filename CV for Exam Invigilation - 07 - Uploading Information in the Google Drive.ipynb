{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Check using IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method for calculating accuracy for single test image.\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "face_cascade = cv.CascadeClassifier('C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\myhaar_p1069n2654s20.xml')\n",
    "img = cv.imread('C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\NB_8.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "boxA = [940,288,1229,594]   #Co-ordinates of image for whch testing is to be done.\n",
    "boxB=[]\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "if type(faces) == tuple:\n",
    "    if all(faces):         #If the face is not present in the image then iou = 0.\n",
    "        iou = 0\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    boxB.append(x)\n",
    "    boxB.append(y)\n",
    "    boxB.append(w+x)\n",
    "    boxB.append(h+y)\n",
    "    iou = bb_intersection_over_union(boxA,boxB)   #Call function to calculate IoU.\n",
    "    boxB = []\n",
    "print(iou)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to calculate IoU.\n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    #print(interArea)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For IoU calculation for multiple images\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "#face_cascade = cv.CascadeClassifier('C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\myhaar_p1069n2654s20.xml')\n",
    "face_cascade = cv.CascadeClassifier('C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\myhaar_1105P_2760N_LF.xml')\n",
    "count = 0\n",
    "dicty = {}\n",
    "for imag in glob.glob(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\For Accuracy Test\\\\TestImg_30082018\\\\*.jpg\"):\n",
    "    img= cv.imread(imag)\n",
    "    imgName = os.listdir(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\For Accuracy Test\\\\TestImg_30082018\")[count] #Get image names of all the files in the directory\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    boxA = getActualFaceCoord(imgName)  #Function which will return the face co-ordinates according to info.txt.\n",
    "    boxB=[]\n",
    "    iou = 0\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if type(faces) == tuple:\n",
    "        if all(faces):        #This line is to check that if the face is not detected then it will be empty. \n",
    "            iou = 0           # If the face is not detected, set the iou to 0.\n",
    "            #print(iou)\n",
    "            dicty[imgName] = iou\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        boxB.append(x)\n",
    "        boxB.append(y)\n",
    "        boxB.append(w+x)\n",
    "        boxB.append(h+y)\n",
    "        iou = bb_intersection_over_union(boxA,boxB)   #Function to calculate iou.\n",
    "        #print(iou)\n",
    "        boxB = []\n",
    "        dicty[imgName] = iou\n",
    "        #break\n",
    "    count += 1\n",
    "    cv.putText(img, \"IoU: {:.4f}\".format(iou), (100, 100), cv.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2)\n",
    "    cv.imwrite(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\For Accuracy Test\\\\DetectedImg\\\\\"+imgName, img)\n",
    "cv.destroyAllWindows()\n",
    "df = pd.DataFrame(list(dicty.items()),columns=[\"Image\",\"Accuracy\"])\n",
    "df.to_excel(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\For Accuracy Test\\\\Detected_Excel\\\\acc_17092018.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to get actual coordinates from info.txt for test images.\n",
    "\n",
    "def getActualFaceCoord(imageName):\n",
    "    fhand = open(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\Praxis\\\\Term3\\\\Capstone\\\\VideoDetect\\\\info.txt\")\n",
    "    boxA = []\n",
    "    imageName = imageName.replace(\".jpg\",'')\n",
    "    for line in fhand:\n",
    "        if(imageName in line):\n",
    "            c = 0\n",
    "            for vals in line.strip().split(' '):  #Need to get only the co-ordinates of the image.\n",
    "                if c > 1:\n",
    "                    boxA.append(int(vals))\n",
    "                c += 1\n",
    "            break\n",
    "    w = boxA[2]\n",
    "    h = boxA[3]\n",
    "    boxA[2] = boxA[0]+w\n",
    "    boxA[3] = boxA[1]+h\n",
    "   \n",
    "    return boxA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
